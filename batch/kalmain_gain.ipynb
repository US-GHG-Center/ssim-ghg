{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6b1dd076-68cd-4772-9cf8-4290e1f225fb",
   "metadata": {},
   "source": [
    "### Exploring the Kalman Gain matrix\n",
    "In this exercise, you start breaking down how individual and sets of observations impact your flux estimates. For this exercise, the NOAA CarbonTracker website, https://gml.noaa.gov/ccgg/carbontracker/co2tser.php will be helpful to map observation ids for in situ data to geographic locations in the world.\n",
    "\n",
    "- Do you see large difference in which sites/observations are more influential in the northern midlatititudes, e.g. Europe and North America, vs the tropics, e.g. Africa and S. America?  Any ideas why?\n",
    "  \n",
    "- For state elements controlling the flux of Northern high latitude regions, e.g. Boreal North America, are satellite or in situ data more valuable? or does it depend?\n",
    "\n",
    "- What about places like Europe or Temperate North America?\n",
    "\n",
    "- Why do places in the southern hemisphere, at same latitude away from equator as U.S. and Europe, e.g. Temp South America, look different than their northern counterparts would you guess?\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61976797-da8e-4c4b-9c9e-52ccb717a4da",
   "metadata": {},
   "source": [
    "#### Setting up Environment for ComputingÂ¶\n",
    "This cell simply looks for whether we are on GHGHub (or local) and sets up environment, including directory references and libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13ce113-a570-4c13-9275-39c197d218a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "#-- Read settings for location of data and set up, NO NEED TO CHANGE\n",
    "######################################################################\n",
    "orig_dir = getwd()\n",
    "require(yaml,warn.conflicts = FALSE)\n",
    "dat = yaml.load_file(\"../site_settings.yml\")\n",
    "Rcode_dir <- getwd()\n",
    "data_dir = paste(dat$global_paths$input_folder,\"/\",sep=\"\")\n",
    "output_dir = paste(dat$global_paths$output_folder,\"/\",sep=\"\")\n",
    "\n",
    "print(paste(\"Using\",data_dir,\"for data directory\"))\n",
    "print(paste(\"Using\",output_dir,\"for output directory\"))\n",
    "\n",
    "#--  Load utility code file w/ setup()\n",
    "source(file.path(Rcode_dir,\"util_code_032024.R\"))\n",
    "setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab410eb9-f60e-4f6e-b365-af09c5be31e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################\n",
    "#--  Load sensitivity matrices \n",
    "###############################################\n",
    "\n",
    "load(file.path(data_dir,\"jacobians/\",\"trunc_full_jacob_030624_with_dimnames_sib4_4x5_mask.rda\"))\n",
    "load(file.path(data_dir,\"jacobians/\",\"jacob_bgd_060524.rda\"))\n",
    "\n",
    "#-- Difference in forward runs from GEOS-CHem resulted in CO2 vs C diff in mass is why 12/44 is here (note)\n",
    "#-- Assign the jacob objects to H to match notation\n",
    "H <- jacob * 12/44\n",
    "H_bgd <- jacob_bgd \n",
    "rm(jacob);rm(jacob_bgd)\n",
    "\n",
    "#-- These represent the fossil and biomass burning contributions to the observations (from fixed emission runs)\n",
    "fire_fixed <- H_bgd[,2]\n",
    "fossil_fixed <- H_bgd[,3]\n",
    "###################################################################\n",
    "#-- END END END ***Parent Directory and code for ALL inversions***\n",
    "###################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88569e4-d10b-4bb5-ba1b-a1d1f0e4f74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##################################################################\n",
    "#- Inversion #1   *************************\n",
    "##################################################################\n",
    "\n",
    "#################################\n",
    "#- Target truth in state space\n",
    "#################################\n",
    "\n",
    "##################################################################\n",
    "#-- This array holds ratios of OCO2v10MIP fluxes and SiB4 fluxes\n",
    "#-- as examples of \"scalings\" to be recovered. It also holds corresponding\n",
    "#-- differences if the inversion attempts to directly solve for flux\n",
    "#-- truth_array(24 months, 23 transcom, 98 inversions, (ratio, difference) )\n",
    "##################################################################\n",
    "\n",
    "#-- Don't Change\n",
    "#load(\"/projects/sandbox/inversion_workshop_scripts/truth_array.rda\")\n",
    "load(file.path(data_dir,\"misc/truth_array.rda\"))\n",
    "#-- pulling out NA transcom region and subset to scalar vs flux adj\n",
    "truth_array = truth_array[,-1,,1]\n",
    "#-- Don't Change\n",
    "\n",
    "\n",
    "#--  Choose our state from inversion list, option #1, and \"truncate\" to -1 and 1\n",
    "inversion_number =1   #  choose this between 1 and 98\n",
    "state_vector_true= tm(as.vector(- truth_array[,,inversion_number]),-1,1)\n",
    "\n",
    "#-- Alternatively choose a \"different\" true state like the below ones\n",
    "#-- The first just means the truth IS the prior, the second has a simple structure\n",
    "#-- Land regions fluxes are (1+0.5) * prior guess and ocean fluxes are (1- 0.5) * prior guess.\n",
    "#state_vector_true = c(rep(0,24*11),rep(0,24*11))\n",
    "#state_vector_true = c(rep(0.5,24*11),rep(-0.5,24*11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f544ec1d-253a-4c42-a33e-ac02f74bd641",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################\n",
    "# Generate a prior flux covariance matrix Sx\n",
    "# These first two lines form \"diagonal\" of Sx, e.g. marginal variances\n",
    "# Long term, a catalog of predefined choices is best here I think\n",
    "#########################################################\n",
    "land_prior_sd = 0.5   #-- free to set this, implies you think \"truth\" for land is within +/- 3*this\n",
    "ocean_prior_sd = 1    #-- free to set this, implies you think \"truth\" for ocean is within +/- 3*this\n",
    "\n",
    "##############################################################################\n",
    "#-- This is the structure of the 24 month subblock for each land/ocean region\n",
    "#-- induce temporal correlations\n",
    "##############################################################################\n",
    "\n",
    "#-- This will set up a prior temporal correlation, \n",
    "#-- free to set month_to_month_correlation between 0 (independent) and 1\n",
    "month_to_month_correlation = 0.5\n",
    "sigma = bdiag(rep(list(ar_covariance(24, month_to_month_correlation)), 22))  #-- free to set \n",
    "\n",
    "\n",
    "#################################################\n",
    "#-- scale by variance for land/ocean (set diagonal of matrix)\n",
    "#-- This simply puts together pieces above\n",
    "#################################################\n",
    "var_scaling_diagonal = diag(c(rep(land_prior_sd,24*11),rep(ocean_prior_sd,24*11)))\n",
    "\n",
    "Sx = as.matrix(var_scaling_diagonal %*% sigma %*% t(var_scaling_diagonal))\n",
    "\n",
    "#-- This is an alternative state_vector_true based *exactly* upon the prior covariance matrix\n",
    "#-- as opposed to being able to pick your \"truth\" separately from your assumed dist where \"truth\" lives\n",
    "#-- Probably don't want to change this unless you know what you are doing\n",
    "#state_vector_true = t(rmvnorm(n=1,mean=rep(0,528),sigma=sigma))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc6f170-3f9c-43b2-9e0c-83c4cc227fca",
   "metadata": {},
   "source": [
    "#### Choose which observations you want to assimilate\n",
    "Or in other words, which observations will be used to optimize/estimate the unknown fluxes.  This problem is somewhat over determined with over a million observations to constrain a 528 element state.  With that in mind, small observation errors and LOTS of observations used should \"nail the unknown\" solution quite well. The goal here is to create a vector of TRUE/FALSE of length equal to the total number of observations described in the sensitivity matrix we loaded above ( 1156383 ). The obs_catalog is a data.frame (think matrix of 'items'), with information about each observation and can be used to build a subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430d1ee9-5842-4e8f-96a7-eb5dfc329d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################\n",
    "#-- WHICH obs do you want to use in the inversion? \n",
    "#-- examples of selecting on stations, type of data, lat/lon box,etc\n",
    "####################################################################################\n",
    "\n",
    "#load(file.path(data_dir,\"obs/obs_catalog_030624.rda\")) # obs_catalog object\n",
    "load(file.path(data_dir,\"obs/obs_catalog_042424_unit_pulse_hour_timestamp_witherrors_withdates.rda\")) \n",
    "\n",
    "\n",
    "subset_indicator_obs=rep(FALSE,dim(H)[1])\n",
    "#subset_indicator_obs=rep(TRUE,dim(jacob)[1])\n",
    "\n",
    "#subset_indicator_obs=c(rep(TRUE,156383),rep(FALSE,1000000))\n",
    "\n",
    "############################\n",
    "#-- SAMPLE BY TYPE EXAMPLE\n",
    "############################\n",
    "#subset_indicator_obs[obs_catalog$TYPE == \"TCCON\"] = TRUE\n",
    "#subset_indicator_obs1 = rep(FALSE,length(subset_indicator_obs))\n",
    "#subset_indicator_obs2 = rep(FALSE,length(subset_indicator_obs))\n",
    "\n",
    "#subset_indicator_obs1[obs_catalog$TYPE == \"OCO2\"] = TRUE\n",
    "#subset_indicator_obs2[seq(1,1156383,by=2)] = TRUE\n",
    "#subset_indicator_obs = subset_indicator_obs1 & subset_indicator_obs2\n",
    "\n",
    "\n",
    "############################\n",
    "#-- SAMPLE BY NOAA STATION EXAMPLE\n",
    "############################\n",
    "#subset_indicator_obs[grep(\"spo\",obs_catalog$ID)] = TRUE\n",
    "#subset_indicator_obs[grep(\"lef\",obs_catalog$ID)] = TRUE\n",
    "\n",
    "############################\n",
    "#-- SAMPLE BY TIME EXAMPLE\n",
    "############################\n",
    "#subset_indicator_obs[obs_catalog$TIME > 8738000] = TRUE\n",
    "\n",
    "############################\n",
    "#-- SAMPLE BY LON & LAT EXAMPLE\n",
    "############################\n",
    "#subset_indicator_obs[obs_catalog$LON < -10 & obs_catalog$LAT > 10] = TRUE\n",
    "\n",
    "#subset_indicator_obs=c(rep(TRUE,1156382),rep(FALSE,1))\n",
    "subset_indicator_obs[seq(1,1156383,by=5)] = TRUE\n",
    "#table(subset_indicator_obs)\n",
    "\n",
    "\n",
    "\n",
    "############################\n",
    "#-- Downsample if necessary\n",
    "############################\n",
    "\n",
    "if(sum(subset_indicator_obs) > 0.5*length(subset_indicator_obs)) {\n",
    "  new_ind = rep(FALSE,length(subset_indicator_obs))\n",
    "  new_ind[sample(x=grep(TRUE,subset_indicator_obs),size=floor(0.5*length(subset_indicator_obs)))] = TRUE\n",
    "  print(paste(\"downsampling from\",sum(subset_indicator_obs),\"to\",\n",
    "              floor(0.5*length(subset_indicator_obs)),\"observations\"))\n",
    "  subset_indicator_obs = new_ind\n",
    "    }\n",
    "\n",
    "#-- LEAVE THIS AS IT SUMMARIZES THE NUMBER OF OBS USED\n",
    "print(paste(\"using\",sum(subset_indicator_obs),\"of\",length(subset_indicator_obs),\"observations\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e52525-cbb5-424b-8dc7-6a7a1a0dffe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "#-- sd for Gaussian i.i.d. errors, jacob is sens matrix\n",
    "##########################################################\n",
    "#R_diagonal_in = rep(3,(dim(jacob)[1]))\n",
    "Sz_diagonal_in = obs_catalog$SD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10db9f7d-5129-48b0-b5e0-39ac59a300f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################\n",
    "#-- Generate obs, 'y',  set.seed() ????\n",
    "#-- currently leaving out bgd and all fixed\n",
    "#-- non-optimizable contributions including fire and fossil\n",
    "#############################################################\n",
    "\n",
    "err = rnorm(length(Sz_diagonal_in),sd=Sz_diagonal_in)\n",
    "z_in = H %*% (1+state_vector_true) + err\n",
    "\n",
    "z_in_centered = H %*% (state_vector_true) + err"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25277386-ddbe-4d90-8f1e-5740a911a0d7",
   "metadata": {},
   "source": [
    "$$\n",
    "\\newcommand{\\transpose}[1]{{#1^{\\scriptscriptstyle T}}} \n",
    "J(x) = \\transpose{(x_0 - x)} {\\Sigma_x\n",
    "}^{-1}(x_0 - x) + \\transpose{(z - Hx)} {\\Sigma_z}^{-1}(z - Hx)\\\\\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\newcommand{\\transpose}[1]{{#1^{\\scriptscriptstyle T}}} \n",
    "\\hat{x} = (\\transpose{H}{\\Sigma_z}^{-1}H + {\\Sigma_x}^{-1})^{-1}(\\transpose{H}{\\Sigma_z}^{-1}(z-Hx)+{\\Sigma_x}^{-1}x_0)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\newcommand{\\transpose}[1]{{#1^{\\scriptscriptstyle T}}} \n",
    "\\Sigma_{\\hat{x}} = {({\\Sigma_x}^{-1} + \\transpose{H}{\\Sigma_z}^{-1}H )}^{-1}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f4de4e-5572-4c49-93cd-d8aa155a3805",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "#-- Run the actual inversion\n",
    "############################\n",
    "\n",
    "ret2  = invert_clean_notation(H=H,Sz_diagonal=Sz_diagonal_in,Sx=Sx,z=z_in,H_bgd=H_bgd,\n",
    "                    subset_indicator_obs=subset_indicator_obs,DOF=FALSE,output_Kalman_Gain=TRUE,\n",
    "                     state_vector_true=state_vector_true)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3913550-9a4f-49cc-bdc3-8a55beab4752",
   "metadata": {},
   "source": [
    "#### Looking at importance via Kalman Gain (find the biggest value in Gain matrix)\n",
    "Here we are identifying the LARGEST value of Kalman Gain, across all observations for each \"state\" element. This most likely is an observation which is in the geographic vicinity of the state element or downwind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35be7133-27b4-4655-a494-36c5abb633f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- This code looks through Kalman Gain for observation with largest gain in the month of interest for that region\n",
    "max_indices = apply(ret2$diags$KGAIN,1,FUN=function(x){(which(abs(x)==max(abs(x))))[1]})\n",
    "max_indices = as.numeric(as.vector(unlist(max_indices)))\n",
    "sts = obs_catalog$ID[subset_indicator_obs][max_indices]\n",
    "typ = obs_catalog$TYPE[subset_indicator_obs][max_indices]\n",
    "\n",
    "for(i in 1:22){\n",
    "    for(j in 1:24){\n",
    "    print(paste(gsub(\" \",\"\",transcom_names[i]),\" month:\",j,\" TYPE:\",typ[(i-1)*24+j],\"  \",sts[(i-1)*24+j],sep=\"\"))    \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb7b50f-9146-42c7-af72-a8ce41674559",
   "metadata": {},
   "source": [
    "#### Looking at importance via Kalman Gain (find which type of obs has biggest *average* impact on state)\n",
    "Here we are plotting the average of the K*(model-z), the \"state adjustment\", across different observation types. For a state element, e.g. North America Temperate for Jul 2016, we average over the state adjustment by each observation type. This gives average impact of the type of observation towards the state. *Values are normalized to sum to one across each month*. Note that this is performed for each state element across ALL global observations available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6739716-30f7-4b97-a51c-23438f4abc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_adjustment_per_obs = t(apply(ret2$diags$KGAIN,1,FUN=function(x){x* z_in_centered[subset_indicator_obs]}))\n",
    "\n",
    "options(repr.plot.width=12, repr.plot.height=8)\n",
    "\n",
    "for(i in 1:22){\n",
    " out = apply(abs(state_adjustment_per_obs[((i-1)*24+1):((i)*24),]),1,\n",
    "             FUN=function(x){aggregate(x,list(obs_catalog$TYPE[subset_indicator_obs]),mean)})\n",
    " out2 = cbind(IS = sapply(out,FUN=function(x){x$x[1]}),\n",
    "              OCO2 = sapply(out,FUN=function(x){x$x[2]}),\n",
    "             TCCON = sapply(out,FUN=function(x){x$x[3]}))\n",
    "    out3 = as.data.frame(t(apply(out2,1,FUN=function(x){return(x/sum(x))})))\n",
    "    plot(1:24,out3$IS,col=\"blue\",type=\"b\",ylim=c(0,1),xaxt=\"none\",ylab=\"Relative impact on state adjustment\",xlab=\"Date\",\n",
    "         main=paste(\"Average impact of 1 observation on state adjustment for:\",transcom_names[i]))\n",
    "    axis(side = 1,labels = dts[seq(1,24,by=6)],at=(1:24)[seq(1,24,by=6)],cex=0.9)\n",
    "    points(1:24,out3$OCO2,col=\"red\",type=\"b\",cex=1.1)\n",
    "    points(1:24,out3$TCCON,col=\"orange\",type=\"b\")\n",
    "    legend(1,1,c(\"IS\",\"OCO2\",\"TCCON\"),col=c(\"blue\",\"red\",\"orange\"),lty=1,pch=1,bg=\"white\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec77e78-07b9-4a24-8e83-78d27f0a1e48",
   "metadata": {},
   "source": [
    "#### Looking at importance via Kalman Gain(find which type of obs has biggest *total* impact on state)\n",
    "Similarly, we are not plotting the *sum* of the K*(model-z), the \"state adjustment\", across different observation types. For a state element, e.g. North America Temperate for Jul 2016, this gives the total impact of the type of observation towards the state, i.e. incorporating the number of observations per type.  *Values are normalized to sum to one across each month*.  Note that this is performed for each state element across ALL global observations available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad047f4-b27d-429e-8afd-33a2ebaecc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_adjustment_per_obs = t(apply(ret2$diags$KGAIN,1,FUN=function(x){x* z_in_centered[subset_indicator_obs]}))\n",
    "options(repr.plot.width=12, repr.plot.height=8)\n",
    "\n",
    "for(i in 1:22){\n",
    " out = apply(abs(state_adjustment_per_obs[((i-1)*24+1):((i)*24),]),1,FUN=function(x){aggregate(x,list(obs_catalog$TYPE[subset_indicator_obs]),sum)})\n",
    " out2 = cbind(IS = sapply(out,FUN=function(x){x$x[1]}),\n",
    "              OCO2 = sapply(out,FUN=function(x){x$x[2]}),\n",
    "             TCCON = sapply(out,FUN=function(x){x$x[3]}))\n",
    "    out3 = as.data.frame(t(apply(out2,1,FUN=function(x){return(x/sum(x))})))\n",
    "    plot(1:24,out3$IS,col=\"blue\",type=\"b\",ylim=c(0,1),xaxt=\"none\",ylab=\"Relative impact on state adjustment\",xlab=\"Date\",\n",
    "         main=transcom_names[i])\n",
    "    axis(side = 1,labels = dts[seq(1,24,by=6)],at=(1:24)[seq(1,24,by=6)],cex=0.9)\n",
    "    points(1:24,out3$OCO2,col=\"red\",type=\"b\",cex=1.1)\n",
    "    points(1:24,out3$TCCON,col=\"orange\",type=\"b\")\n",
    "    legend(1,1,c(\"IS\",\"OCO2\",\"TCCON\"),col=c(\"blue\",\"red\",\"orange\"),lty=1,pch=1,bg=\"white\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19aba0ef-85ca-417f-8993-f1ffdc506862",
   "metadata": {},
   "outputs": [],
   "source": [
    "sessionInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66066cd8-1b6b-4ee5-a8f6-928d26e626e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "R"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
