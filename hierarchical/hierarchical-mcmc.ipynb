{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8c92008-fd6c-44c7-a6f5-cbb6e8fcd6e8",
   "metadata": {},
   "source": [
    "**Start by running the following preamble code block:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c04d472-3102-4490-a2fb-8108952b7da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(dplyr, warn.conflicts = FALSE)\n",
    "library(Matrix)\n",
    "library(ggplot2)\n",
    "library(lubridate, warn.conflicts = FALSE)\n",
    "if(!require('gridExtra', warn.conflicts = FALSE)) {\n",
    "    install.packages('gridExtra')\n",
    "    library(gridExtra)\n",
    "}\n",
    "if(!require('numDeriv', warn.conflicts = FALSE)) {\n",
    "    install.packages('numDeriv')\n",
    "    library(numDeriv)\n",
    "}\n",
    "\n",
    "theme_set(theme_bw())\n",
    "\n",
    "data_dir <-  '~/shared/ssim-ghg-data/inversion_examples'\n",
    "\n",
    "n_land_regions <- 11\n",
    "n_ocean_regions <- 11\n",
    "n_months <- 24\n",
    "\n",
    "source('utilities.R')\n",
    "source('setup-obs-and-jacobian.R')\n",
    "load(file.path(data_dir, 'misc', 'truth_array.rda'))\n",
    "truth_array <- truth_array[, -1, , 1]\n",
    "inversion_number <- 44\n",
    "x_true <- pmax(pmin(as.vector(-truth_array[, , inversion_number]), 5), -5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d590d38-7dea-47d6-bd1b-f66b541043f0",
   "metadata": {},
   "source": [
    "# A hierarchical model extension of the toy problem\n",
    "\n",
    "In this notebook, we extend the model underlying the batch inverson to have a hierarchical component, and estimate its parameters using Markov chain Monte Carlo (MCMC).\n",
    "\n",
    "## The base batch model\n",
    "\n",
    "The base batch model is\n",
    "\\begin{align*}\n",
    "    (\\mathbf{z} \\mid \\mathbf{x})\n",
    "    & \\sim \\mathcal{N}(\\mathbf{H} \\mathbf{x}, \\mathbf{S}_z), \\\\\n",
    "    \\mathbf{x}\n",
    "    & \\sim \\mathcal{N}(\\mathbf{x}_0, \\mathbf{S}_0), \\\\\n",
    "\\end{align*}\n",
    "where $\\mathbf{z} = (z_1, \\ldots, z_{n_z})^T$ contains the $n_z$ observations, $\\mathbf{H}$ is the $n_z \\times n_x$ Jacobian matrix, $\\mathbf{x} = (x_1, \\ldots, x_{n_x})^T$ contains the $n_x$ entries of the state vector, $\\mathbf{x}_0$ is the state vector prior mean, and $\\mathbf{S}_0$ is the state vector prior covariance matrix.\n",
    "\n",
    "For simplicity, we have that $\\mathbf{x}_0 = (0, \\ldots, 0)^T$, and that $\\mathbf{S}_z$ is a diagonal matrix. \n",
    "\n",
    "The inversion occurs over 24 months and the state vector $\\mathbf{x}$ has entries for each of the 22 TransCom regions and for each of the 24 months from 2014-09 to 2016-08 (therefore, it has 528 entries). The entries are organized region-by-region and month-by-month in $\\mathbf{x}$:\n",
    "$$\n",
    "    \\mathbf{x} = (\\text{region 1 in month 2014-09}, \\text{region 1 in month 2014-10}, \\ldots, \\text{region 1 in month 2016-08}, \\ldots, \\text{region 22 in month 2016-08})^T\n",
    "$$\n",
    "\n",
    "Let's unpack each of the pieces below.\n",
    "\n",
    "## Flux prior\n",
    "\n",
    "We set $\\mathbf{S}_0$ so that the entries within each region are correlated in time, but there is no correlation between regions. The first 11 regions correspond to land regions, and the last 11 regions to ocean regions; we allow for land and ocean to have different variance and correlation. Overall, then, $\\mathbf{S}_0$ has the structure\n",
    "$$\n",
    "    \\mathbf{S}_0 = \\begin{pmatrix}\n",
    "        \\mathbf{S}_0^\\text{land}\n",
    "        & \\\\\n",
    "        & \\ddots \\\\\n",
    "        & & \\mathbf{S}_0^\\text{land} \\\\\n",
    "        & & & \\mathbf{S}_0^\\text{ocean} \\\\\n",
    "        & & & & \\ddots \\\\\n",
    "        & & & & & \\mathbf{S}_0^\\text{ocean}\n",
    "    \\end{pmatrix}\n",
    "$$\n",
    "where\n",
    "$$\n",
    "  \\mathbf{S}_0^\\text{land} = \\tau_\\text{land}^2 \\begin{pmatrix}\n",
    "    1 & \\rho_\\text{land} & \\rho_\\text{land}^2 & \\cdots & \\rho_\\text{land}^{23} \\\\\n",
    "    \\rho_\\text{land} & 1 & \\rho_\\text{land} & \\cdots & \\rho_\\text{land}^{22} \\\\\n",
    "    \\rho_\\text{land}^2 & \\rho_\\text{land} & 1 & \\cdots & \\rho_\\text{land}^{21} \\\\\n",
    "    \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    \\rho_\\text{land}^{23} & \\rho_\\text{land}^{22} & \\rho_\\text{land}^{21} & \\cdots & 1\n",
    "  \\end{pmatrix}.\n",
    "$$\n",
    "Here, $\\tau_\\text{land} > 0$ is the land standard deviation; $-1 < \\rho_\\text{land} < 1$ is the land autocorrelation; and $\\mathbf{S}_0^\\text{ocean}$ is defined identically except with parameters $\\tau_\\text{ocean}$ and $\\rho_\\text{ocean}$.\n",
    "\n",
    "**The following function produces this covariance matrix:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0660f4-a2be-4a48-a40d-e408e71de2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the covariance matrix of an AR(1) process\n",
    "ar1_covariance <- function(n, rho, stdev = 1) {\n",
    "  (stdev ^ 2) * toeplitz(rho ^ (0 : (n - 1)))\n",
    "}\n",
    "\n",
    "# Construct the prior covariance matrix. The vector parameter theta contains\n",
    "# - theta[1]: observation error standard deviation (sigma)\n",
    "# - theta[2]: land standard deviation (tau_land^2)\n",
    "# - theta[3]: land correlation (rho_land)\n",
    "# - theta[4]: ocean standard deviation (tau_ocean^2)\n",
    "# - theta[5]: ocean correlation (rho_ocean)\n",
    "get_S0 <- function(theta) {\n",
    "  S0_land <- ar1_covariance(n_months, theta[3], theta[2])\n",
    "  S0_ocean <- ar1_covariance(n_months, theta[5], theta[4])\n",
    "  n_dim <- n_months * (n_land_regions + n_ocean_regions)\n",
    "  output <- matrix(0, nrow = n_dim, ncol = n_dim)\n",
    "  for (i in seq_len(n_land_regions + n_ocean_regions)) {\n",
    "    start <- (i - 1) * n_months + 1\n",
    "    end <- i * n_months\n",
    "    if (i <= n_land_regions) {\n",
    "      output[start:end, start:end] <- S0_land\n",
    "    } else {\n",
    "      output[start:end, start:end] <- S0_ocean\n",
    "    }\n",
    "  }\n",
    "  output\n",
    "}\n",
    "\n",
    "S0_example <- get_S0(c(3, 1.5, 0.9, 1, 0.7))\n",
    "options(repr.plot.width = 11, repr.plot.height = 4, repr.plot.res = 200)\n",
    "gridExtra::grid.arrange(\n",
    "    lattice::levelplot(S0_example, xlab = 'Column', ylab = 'Row', ylim=c(528.5, 0.5), main = expression(S[0])),\n",
    "    lattice::levelplot(S0_example[1 : 24, 1 : 24], xlab = 'Column', ylab = 'Row', ylim=c(24.5, 0.5), main = expression(S[0]^'land')),\n",
    "    nrow = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335483eb-89da-46a8-8ba5-520f6c44029a",
   "metadata": {},
   "source": [
    "## Observation error covariance\n",
    "\n",
    "For the observation error covariance, we assume that\n",
    "$$\n",
    "\\mathbf{S}_z = \\sigma^2 \\begin{pmatrix}\n",
    "  1 \\\\\n",
    "  & \\ddots \\\\\n",
    "  & & 1\n",
    "\\end{pmatrix}.\n",
    "$$\n",
    "\n",
    "This means that all observations get the same error standard deviation $\\sigma^2$.\n",
    "\n",
    "## Parameter prior\n",
    "\n",
    "Our unknown parameters are therefore ${\\boldsymbol \\theta} = (\\sigma, \\tau_\\mathrm{land}, \\rho_\\mathrm{land}, \\tau_\\mathrm{ocean}, \\rho_\\mathrm{land})^T$. We need to set a prior on these components. We choose the following:\n",
    "\\begin{gather}\n",
    "  \\sigma \\sim \\mathrm{Half}\\text{-}\\mathcal{N}(3^2),\n",
    "  \\quad \\tau_\\mathrm{land} \\sim \\mathrm{Half}\\text{-}\\mathcal{N}(3^2),\n",
    "  \\quad \\tau_\\mathrm{ocean} \\sim \\mathrm{Half}\\text{-}\\mathcal{N}(3^2) \\\\\n",
    "  \\rho_\\mathrm{land} \\sim \\mathrm{Unif}(-1, 1),\n",
    "  \\quad \\rho_\\mathrm{ocean} \\sim \\mathrm{Unif}(-1, 1).\n",
    "\\end{gather}\n",
    "**These are visualized below:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6701de50-3ebe-47fe-99aa-f41709e97d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width = 6, repr.plot.height = 2, repr.plot.res = 300)\n",
    "gridExtra::grid.arrange(\n",
    "  ggplot() +\n",
    "    geom_function(\n",
    "      fun = function(x) 2 * dnorm(x, sd = 3),\n",
    "      xlim = c(0, 12)\n",
    "    ) +\n",
    "    labs(x = expression(sigma*' / '*tau['land']*' / '*tau['ocean']), y = 'Density'),\n",
    "  ggplot() +\n",
    "    geom_function(\n",
    "      fun = function(x) ifelse(x < -1 | x > 1, 0, 0.5),\n",
    "      xlim = c(-2, 2),\n",
    "      n = 1001\n",
    "    ) +\n",
    "    ylim(0, 1) +\n",
    "    labs(x = expression(rho['land']*' / '*rho['ocean']), y = 'Density'),\n",
    "  nrow = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aedc2b7-8ca1-4ecd-b603-a8f8c91968e0",
   "metadata": {},
   "source": [
    "You can see that for the standard deviations (left plot), the prior distribution admits be anything between 0 and 10. For the correlation, the value can be anything between -1 and 1.\n",
    "\n",
    "To investigate what this prior says about the fluxes, we can perform a Monte Carlo experiment (this is not Markov chain Monte Carlo! We do that later):\n",
    "1. Simulate $\\boldsymbol \\theta$ from its prior\n",
    "2. Simulate $\\mathbf{x}$ from $p(\\mathbf{x} \\mid \\boldsymbol \\theta)$\n",
    "\n",
    "The following code does this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27bbbdc-a3da-4c5f-8570-2f48db8307cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_prior_sd <- 3\n",
    "tau_land_prior_sd <- 3\n",
    "tau_ocean_prior_sd <- 3\n",
    "theta_names <- c('sigma', 'tau_land', 'rho_land', 'tau_ocean', 'rho_ocean')\n",
    "\n",
    "n_samples <- 2000L\n",
    "theta_samples_prior <- matrix(NA, nrow = n_samples, ncol = 5)\n",
    "colnames(theta_samples_prior) <- theta_names\n",
    "x_samples_prior <- matrix(NA, nrow = n_samples, ncol = ncol(H))\n",
    "for (iteration in seq_len(n_samples)) {\n",
    "  theta <- c(\n",
    "    abs(rnorm(1, sd = sigma_prior_sd)),\n",
    "    abs(rnorm(1, sd = tau_land_prior_sd)),\n",
    "    runif(1, -1, 1),\n",
    "    abs(rnorm(1, sd = tau_ocean_prior_sd)),\n",
    "    runif(1, -1, 1) \n",
    "  )\n",
    "  S0 <- get_S0(theta)\n",
    "  x <- rmvnorm(rep(0, ncol(H)), S = S0)\n",
    "  theta_samples_prior[iteration, ] <- theta    \n",
    "  x_samples_prior[iteration, ] <- x\n",
    "}\n",
    "\n",
    "print(head(theta_samples_prior))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9d87ee-cb7c-461b-8dc5-212888a2d497",
   "metadata": {},
   "source": [
    "We can look at global total monthly land and ocean fluxes and their prior 95% intervals to see what this prior says:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8809cf64-1a94-4900-a0b8-0e09b4b69ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_to_land_ocean_flux is defined in utilities.R\n",
    "land_ocean_flux_true <- x_to_land_ocean_flux(x_true)\n",
    "land_ocean_flux_prior <- x_to_land_ocean_flux(rep(0, ncol(H)), x_samples_prior)\n",
    "\n",
    "options(repr.plot.width = 6, repr.plot.height = 3.5, repr.plot.res = 300)\n",
    "bind_rows(\n",
    "    land_ocean_flux_true %>%\n",
    "        mutate(source = 'Truth'),\n",
    "    land_ocean_flux_prior %>%\n",
    "        mutate(source = 'Prior')    \n",
    ") %>%\n",
    "    ggplot(aes(time, colour = source)) +\n",
    "        geom_line(mapping = aes(y = flux)) +\n",
    "        geom_line(mapping = aes(y = flux_q025), linetype = 'dashed', na.rm = TRUE) +\n",
    "        geom_line(mapping = aes(y = flux_q975), linetype = 'dashed', na.rm = TRUE) +\n",
    "        facet_wrap(~ region_type, ncol = 1, scales = 'free_y') +\n",
    "        labs(x = 'Time', y = 'Flux [PgC/year]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96ab502-081b-4771-bc28-dc651a148ccf",
   "metadata": {},
   "source": [
    "In terms of CO2, this is a pretty uninformative prior, particularly for land."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136a11be-ce5a-4c47-8f98-20bc876de81c",
   "metadata": {},
   "source": [
    "## The full model, and its posterior\n",
    "\n",
    "We can now write the full model as:\n",
    "\\begin{gather}\n",
    "    (\\mathbf{z} \\mid \\mathbf{x}, \\sigma)\n",
    "    \\sim \\mathcal{N}(\\mathbf{H} \\mathbf{x}, \\mathbf{S}_z), \\\\\n",
    "    (\\mathbf{x} \\mid \\tau_\\mathrm{land}, \\rho_\\mathrm{land}, \\tau_\\mathrm{ocean}, \\rho_\\mathrm{ocean}),\n",
    "    \\sim \\mathcal{N}{(\\mathbf{x}_0,\\mathbf{S}_0)} \\\\\n",
    "    \\sigma \\sim \\mathrm{Half}\\text{-}\\mathcal{N}(3^2),\n",
    "          \\quad \\tau_\\mathrm{land} \\sim \\mathrm{Half}\\text{-}\\mathcal{N}(3^2),\n",
    "          \\quad \\tau_\\mathrm{ocean} \\sim \\mathrm{Half}\\text{-}\\mathcal{N}(3^2) \\\\\n",
    "    \\rho_\\mathrm{land} \\sim \\mathrm{Unif}(-1, 1),\n",
    "          \\quad \\rho_\\mathrm{ocean} \\sim \\mathrm{Unif}(-1, 1).\n",
    "\\end{gather}\n",
    "\n",
    "In the slides, we derive the log posterior distribution $\\log p({\\boldsymbol \\theta} \\mid \\mathbf{z})$ to be:\n",
    "$$\n",
    "    \\log p({\\boldsymbol \\theta} \\mid \\mathbf{z})\n",
    "    = \\log p(\\mathbf{z} \\mid {\\boldsymbol \\theta}) + \\log p({\\boldsymbol \\theta}) + C,\n",
    "$$\n",
    "where $\\log p(\\mathbf{z} \\mid {\\boldsymbol \\theta})$ is given by\n",
    "$$\n",
    "    \\log p(\\mathbf{z} \\mid {\\boldsymbol \\theta}) =\n",
    "    -\\frac{1}{2}\\log |\\mathbf{H}\\mathbf{S}_0\\mathbf{H}^T+\\mathbf{S}_z| -\n",
    "      \\frac{1}{2}\n",
    "        \\tilde{\\mathbf{z}}^T\n",
    "        (\\mathbf{H}\\mathbf{S}_0\\mathbf{H}^T+\\mathbf{S}_z)^{-1}\n",
    "        \\tilde{\\mathbf{z}}\n",
    "    + C_2.\n",
    "$$\n",
    "where $\\tilde{\\mathbf{z}} = \\mathbf{z} - \\mathbf{H}\\mathbf{x}_0$ and $C_2$ is another constant. The notes show how this can be computed efficiently using the Woodbury matrix identity; the result is:\n",
    "\\begin{align*}\n",
    "    \\log |\\mathbf{S}_z + \\mathbf{H} \\mathbf{S}_0 \\mathbf{H}^T|\n",
    "    & = \\log |\\mathbf{O}| + \\log |\\mathbf{S_z}| + \\log |\\mathbf{S}_0| \\\\\n",
    "    \\tilde{\\mathbf{z}}^T\n",
    "    (\\mathbf{H}\\mathbf{S}_0\\mathbf{H}^T+\\mathbf{S}_z)^{-1}\n",
    "    \\tilde{\\mathbf{z}}\n",
    "    & = \\tilde{\\mathbf{z}}^T \\mathbf{S}_z^{-1}   \\tilde{\\mathbf{z}}\n",
    "        - \\tilde{\\mathbf{z}}^T \\mathbf{S}_z^{-1} \\mathbf{H} \\mathbf{O}^{-1} \\mathbf{H}^T \\mathbf{S}_z^{-1}     \\tilde{\\mathbf{z}}.\n",
    "\\end{align*}\n",
    "\n",
    "The other part of the posterior, $\\log p({\\boldsymbol \\theta})$, can be computed using standard functions in R.\n",
    "\n",
    "Code to compute $\\log p({\\boldsymbol \\theta} \\mid \\mathbf{z})$ up to the unknown constant $C$ appears later in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcdcdc6-4d0e-4608-9d14-270b3245734c",
   "metadata": {},
   "source": [
    "# Simulated data for this experiment\n",
    "\n",
    "Shortly we will start doing some inversions. For those inversions, we need some data.\n",
    "\n",
    "Although fluxes are estimated from 2014-09 to 2016-08, we only use data up to 2015-08. We will use this later to see what the posterior distribution is for the fluxes after 2015-08, when there is no data. The number of observations (and their type, OCO-2 or in situ) is shown in the following plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c98fa1-6ab6-40e6-a443-30a432e19414",
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width = 7, repr.plot.height = 2, repr.plot.res = 300)\n",
    "expand.grid(\n",
    "  time = seq(ymd_hms('2014-09-01 00:00:00'), ymd_hms('2016-08-01 00:00:00'), by = 'month'),\n",
    "  TYPE = unique(obs_catalog$TYPE),\n",
    "  stringsAsFactors = FALSE\n",
    ") %>%\n",
    "  left_join(\n",
    "    obs_catalog %>%\n",
    "      group_by(TYPE, time = floor_date(DATE, 'month')) %>%\n",
    "      summarise(n = n(), .groups = 'drop'),\n",
    "    by = c('time', 'TYPE')\n",
    "  ) %>%\n",
    "  mutate(n = ifelse(is.na(n), 0, n)) %>%\n",
    "    ggplot(aes(time, n, colour = TYPE)) +\n",
    "      geom_line() +\n",
    "      geom_point() +\n",
    "      labs(x = 'Time', y = 'Number of observations')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d4a6d9-ab2d-44e2-bebc-95a52680384f",
   "metadata": {},
   "source": [
    "We hypothesize \"true\" fluxes under a hypothesized \"true\" error distribution. Assume $\\mathbf{x}_\\mathrm{true}$ is the true flux; we simulate\n",
    "$$\n",
    "  z_\\mathrm{sim} = \\mathbf{H} \\mathbf{x}_\\mathrm{true} + {\\boldsymbol \\epsilon}_\\mathrm{sim}\n",
    "$$\n",
    "where ${\\boldsymbol \\epsilon}_\\mathrm{sim} = (\\epsilon_1^\\mathrm{true}, \\ldots, \\epsilon_{n_z}^\\mathrm{true})^T$, and we simulate $\\epsilon_i^\\mathrm{true}$ from $\\mathcal{N}(0, \\sigma_\\mathrm{true}^2)$.\n",
    "\n",
    "In the code below, $\\mathbf{H}$ was loaded earlier, in the preamble, and we set $\\sigma_\\mathrm{true} = 3$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df882572-696a-4a00-a334-daf1abef4835",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_true <- 3\n",
    "z_sim <- as.vector(H %*% x_true) + rnorm(nrow(H), sd = sigma_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6b4920-8d4c-42ef-b5c4-515e27449ca1",
   "metadata": {},
   "source": [
    "# Estimating the parameters\n",
    "\n",
    "We start by giving the function to compute $\\log p({\\boldsymbol \\theta} \\mid \\mathbf{z})$ (it also returns some other useful quantities):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f66906-ad71-4fe1-930d-ead0294d2a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precalculate H^T H and H^T z\n",
    "Ht_H <- crossprod(H)\n",
    "Ht_z <- crossprod(H, z_sim)\n",
    "\n",
    "# NOTE: chol_solve is defined in utilities.R\n",
    "log_posterior <- function(theta) {\n",
    "  if(\n",
    "    theta[1] <= 0\n",
    "    || theta[2] <= 0\n",
    "    || theta[3] <= -1 || theta[3] >= 1\n",
    "    || theta[4] <= 0\n",
    "    || theta[5] <= -1 || theta[5] >= 1\n",
    "  ) {\n",
    "    return(list(\n",
    "      log_density = -Inf\n",
    "    ))\n",
    "  }\n",
    "\n",
    "  S0 <- get_S0(theta)\n",
    "  chol_S0 <- chol(S0)\n",
    "  Q0 <- chol2inv(chol_S0)\n",
    "  O <- Ht_H / theta[1] ^ 2 + Q0\n",
    "  chol_O <- chol(O)\n",
    "  x_hat <- as.vector(chol_solve(chol_O, Ht_z / theta[1] ^ 2))\n",
    "\n",
    "  woodbury_lhs <- crossprod(z_sim) / theta[1] ^ 2\n",
    "  woodbury_rhs <- crossprod(Ht_z, x_hat) / theta[1] ^ 2\n",
    "  woodbury_log_det <- (\n",
    "    2 * sum(log(diag(chol_O)))\n",
    "    + 2 * sum(log(diag(chol_S0)))\n",
    "    + 2 * length(z_sim) * log(theta[1])\n",
    "  )\n",
    "\n",
    "  log_density <- as.vector(\n",
    "    - 0.5 * woodbury_log_det\n",
    "    - 0.5 * woodbury_lhs\n",
    "    + 0.5 * woodbury_rhs\n",
    "    + dnorm(theta[1], mean = 0, sd = sigma_prior_sd, log = TRUE)\n",
    "    + dnorm(theta[2], mean = 0, sd = tau_land_prior_sd, log = TRUE)\n",
    "    + dnorm(theta[4], mean = 0, sd = tau_ocean_prior_sd, log = TRUE)\n",
    "  )\n",
    "\n",
    "  list(\n",
    "    log_density = log_density,\n",
    "    x_hat = x_hat,\n",
    "    chol_O = chol_O\n",
    "  )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15659b18-89a4-480a-9c56-2e1c4316b849",
   "metadata": {},
   "source": [
    "For this problem, this function is pretty fast; it's run time depends on $n_x$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fbd803-6fad-4431-925d-bd09e923ff38",
   "metadata": {},
   "outputs": [],
   "source": [
    "system.time(print(log_posterior(c(3, 1, 0.1, 1, 0.1))$log_density))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1bcbae-cc07-468c-afc0-14bd7fe62b2f",
   "metadata": {},
   "source": [
    "## Finding the posterior mode\n",
    "\n",
    "We can now just use a generic optimization routine to find the posterior mode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415c9052-75be-434d-ad17-9d6e41dc7309",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit <- nlminb(\n",
    "  c(1, 1, 0, 1, 0),\n",
    "  function(theta) {\n",
    "    -log_posterior(theta)$log_density\n",
    "  },\n",
    "  control = list(trace = 2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6435373c-09f9-48ea-a5cb-e1ac21ce0561",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_mode <- fit$par\n",
    "names(theta_mode) <- c('sigma', 'tau_land', 'rho_land', 'tau_ocean', 'rho_ocean')\n",
    "print(theta_mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4937a2-b213-4da7-a404-a90b0d2b28db",
   "metadata": {},
   "source": [
    "We can use this estimate of $\\boldsymbol \\theta$ to find an estimate of $\\mathbf{x}$, which comes from the conditional distribution $p(\\mathbf{x} \\mid {\\boldsymbol \\theta} = \\hat{\\boldsymbol \\theta}, \\mathbf{z})$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910bb073-68a7-4c88-806e-6c6ecabf2e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "S0_mode <- get_S0(theta_mode)\n",
    "Q_hat_mode <- Ht_H / theta_mode[1] ^ 2 + solve_sym(S0_mode)\n",
    "S_hat_mode <- solve_sym(Q_hat_mode)\n",
    "chol_S_hat_mode <- chol(S_hat_mode)\n",
    "x_hat_mode <- as.vector(solve_sym(Q_hat_mode, Ht_z / theta_mode[1] ^ 2))\n",
    "print(head(x_hat_mode))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed89991-096a-4433-9d4b-51089ded9eb0",
   "metadata": {},
   "source": [
    "We can draw samples from $p(\\mathbf{x} \\mid {\\boldsymbol \\theta} = \\hat{\\boldsymbol \\theta}, \\mathbf{z})$, and look at the land/ocean global total fluxes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ee6ddd-ce04-4d87-b681-46b0322b07f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_samples_mode <- t(replicate(n_samples, rmvnorm(x_hat_mode, chol_S = chol_S_hat_mode)))\n",
    "\n",
    "land_ocean_flux_mode <- x_to_land_ocean_flux(x_hat_mode, x_samples_mode)\n",
    "\n",
    "options(repr.plot.width = 6, repr.plot.height = 3.5, repr.plot.res = 300)\n",
    "bind_rows(\n",
    "    land_ocean_flux_true %>%\n",
    "        mutate(source = 'Truth'),\n",
    "    land_ocean_flux_prior %>%\n",
    "        mutate(source = 'Prior'),\n",
    "    land_ocean_flux_mode %>%\n",
    "        mutate(source = 'Posterior (based on mode)')    \n",
    ") %>%\n",
    "    ggplot(aes(time, colour = source)) +\n",
    "        geom_line(mapping = aes(y = flux)) +\n",
    "        geom_line(mapping = aes(y = flux_q025), linetype = 'dashed', na.rm = TRUE) +\n",
    "        geom_line(mapping = aes(y = flux_q975), linetype = 'dashed', na.rm = TRUE) +\n",
    "        facet_wrap(~ region_type, ncol = 1, scales = 'free_y') +\n",
    "        labs(x = 'Time', y = 'Flux [PgC/year]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5b6607-1c10-4879-be58-c7b485a68131",
   "metadata": {},
   "source": [
    "A few things stand out here:\n",
    "1. The ocean is much less constrained by data than the land\n",
    "2. The uncertainty in the posterior is much less for the first 12 months, when we have data\n",
    "3. The posterior uncertainty for the second 12 months is much less in the posterior, because we have locked down ${\\boldsymbol \\theta}$ to a reasonable value. This uncertainty also looks quite reasonable: it contains the truth."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d38cb46-c9d0-44ad-9d77-556c981cd0a3",
   "metadata": {},
   "source": [
    "## Running Markov chain Monte Carlo\n",
    "\n",
    "As described in the slides, we can use a Metropolis Hastings Markov chain Monte Carlo method to infer the parameters and their uncetainty.\n",
    "\n",
    "The algorithm works as follows: for $k = 1, \\ldots, K$ iterations,\n",
    "1. Draw ${\\boldsymbol \\theta}^*$ from a symmetrical proposal distribution $q({\\boldsymbol \\theta}^* \\mid {\\boldsymbol \\theta}^{[k]})$\n",
    "2. Calculate $\\alpha = \\min\\left\\{ 1, p({\\boldsymbol \\theta}^* \\mid \\mathbf{z}) / p({\\boldsymbol \\theta}^{[k]} \\mid \\mathbf{z}) \\right\\}$\n",
    "3. With probability $\\alpha$, set ${\\boldsymbol \\theta}^{[k+1]}={\\boldsymbol \\theta}^*$; otherwise, set ${\\boldsymbol \\theta}^{[k+1]} = {\\boldsymbol \\theta}^{[k]}$\n",
    "\n",
    "Once you run this procedure, ${\\boldsymbol \\theta}^{[1]}, \\ldots, {\\boldsymbol \\theta}^{[K]}$ constitute a sample from $p({\\boldsymbol \\theta} \\mid \\mathbf{z})$.\n",
    "\n",
    "A key choice for this algorithm is the proposal distribution $q({\\boldsymbol \\theta}^* \\mid {\\boldsymbol \\theta}^{[k]})$. Usually, the idea is to perturb ${\\boldsymbol \\theta}^{[k]}$ to produce a new state that's similar but different to it. A very common choice, which is symmetrical, is:\n",
    "$$\n",
    "    q({\\boldsymbol \\theta}^* \\mid {\\boldsymbol \\theta}^{[k]})\n",
    "    \\sim \\mathcal{N}({\\boldsymbol \\theta}^{[k]}, \\mathbf{S}_q),\n",
    "$$\n",
    "where $\\mathbf{S}_q$ is a covariance matrix. You can think of this as a \"jump\" distribution away from ${\\boldsymbol \\theta}^{[k]}$, where the jump distribution is based on a normal distribution.\n",
    "\n",
    "This choice involves trade-offs: if the proposal distribution doesn't move far from ${\\boldsymbol \\theta}^{[k]}$, the algorithm will be slow to converge. This corresponds to having small diagonals in $\\mathbf{S}_q$. On the other hand, if it moves too far (large diagonals in $\\mathbf{S}_q$), the proposals may not be accepted in step 2.\n",
    "\n",
    "A good way to choose $\\mathbf{S}_q$ is to set it to an approximation of the posterior covariance. One way, which sometimes works, to get this, is to set $\\mathbf{S}_q$ to the negative inverse Hessian matrix of $\\log p({\\boldsymbol \\theta} \\mid \\mathbf{z})$, evauated at the mode, or\n",
    "$$\n",
    "  \\mathbf{S}_q = \\left[ -\\frac{\\delta^2}{\\delta ({\\boldsymbol \\theta})^2} \\log p({\\boldsymbol \\theta} \\mid \\mathbf{z}) \\Bigg|_{{\\boldsymbol \\theta} = \\hat{{\\boldsymbol \\theta}}} \\right]^{-1}.\n",
    "$$\n",
    "This turns out to be a good idea for this problem. The code below finds this matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8b1964-a1e9-4529-b277-d534febbd775",
   "metadata": {},
   "outputs": [],
   "source": [
    "hessian <- numDeriv::hessian(\n",
    "  function(theta) log_posterior(theta)$log_density,\n",
    "  theta_mode\n",
    ")\n",
    "S_q <- solve(-hessian)\n",
    "rownames(S_q) <- theta_names\n",
    "colnames(S_q) <- theta_names\n",
    "print(S_q)\n",
    "print(sqrt(diag(S_q)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d836b7-ec90-4f07-a19e-1090b017b0c9",
   "metadata": {},
   "source": [
    "With that in hand, the following code implements the MCMC sampler. This may take a little while to run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba7e23d-01f1-4065-a3d3-133c050348f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_warm_up <- 200L\n",
    "n_samples_total <- n_warm_up + n_samples\n",
    "theta_samples_all <- matrix(NA, nrow = n_samples_total, ncol = 5)\n",
    "colnames(theta_samples_all) <- theta_names\n",
    "x_samples_all <- matrix(NA, nrow = n_samples_total, ncol = ncol(H))\n",
    "\n",
    "n_accept <- 0L\n",
    "theta_current <- theta_mode\n",
    "log_posterior_current <- log_posterior(theta_current)\n",
    "\n",
    "for (iteration in seq_len(n_samples_total)) {\n",
    "  # Use Metropolis-Hastings to sample theta from p(\\theta | z)\n",
    "  theta_proposed <- rmvnorm(theta_current, S = S_q)\n",
    "  log_posterior_proposed <- log_posterior(theta_proposed)\n",
    "  log_ratio <- log_posterior_proposed$log_density - log_posterior_current$log_density\n",
    "  if (log(runif(1)) < log_ratio) {\n",
    "    n_accept <- n_accept + 1L\n",
    "    theta_current <- theta_proposed\n",
    "    log_posterior_current <- log_posterior_proposed\n",
    "  }\n",
    "\n",
    "  # Sample x from p(x | \\theta, z)\n",
    "  x_current <- rmvnorm(\n",
    "    log_posterior_current$x_hat,\n",
    "    chol_S_inv = log_posterior_current$chol_O\n",
    "  )\n",
    "\n",
    "  theta_samples_all[iteration, ] <- theta_current\n",
    "  x_samples_all[iteration, ] <- x_current\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb34e52-2d75-48c1-8d49-e3cd229a5407",
   "metadata": {},
   "source": [
    "Usually we throw away the first few hundred samples to allow the algorithm to convert:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd554ead-c562-4cc0-bfae-7230335bc9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_samples <- tail(theta_samples_all, -n_warm_up)\n",
    "x_samples <- tail(x_samples_all, -n_warm_up)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed272030-d5b9-4769-8eec-1e63a6532dca",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "We can now look at traceplots and histograms of the inferred parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51da6ed2-7b34-455f-bd6f-bfe22812f7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_traceplots <- lapply(1 : 5, function(i) {\n",
    "  theta_i <- theta_samples[, i]\n",
    "  ggplot(data.frame(\n",
    "    iteration = seq_along(theta_i),\n",
    "    x = theta_i\n",
    "  ), aes(iteration, x)) +\n",
    "    geom_line() +\n",
    "    labs(x = 'Iteration', y = theta_names[i])\n",
    "})\n",
    "\n",
    "theta_histograms <- lapply(1 : 5, function(i) {\n",
    "  theta_i <- theta_samples[, i]\n",
    "  ggplot(data.frame(x = theta_i), aes(x)) +\n",
    "    geom_histogram(\n",
    "      mapping = aes(y = after_stat(density)),\n",
    "      bins = 15\n",
    "    ) +\n",
    "    labs(x = theta_names[i], y = 'Density')\n",
    "})\n",
    "\n",
    "options(repr.plot.width = 7, repr.plot.height = 5, repr.plot.res = 300)\n",
    "gridExtra::grid.arrange(\n",
    "    grobs = list(\n",
    "        theta_traceplots[[1]], theta_histograms[[1]],\n",
    "        theta_traceplots[[2]], theta_histograms[[2]],\n",
    "        theta_traceplots[[3]], theta_histograms[[3]],\n",
    "        theta_traceplots[[4]], theta_histograms[[4]],\n",
    "        theta_traceplots[[5]], theta_histograms[[5]]\n",
    "    ),\n",
    "    nrow = 5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1bae78-efbf-4bea-b096-a12b051e47b6",
   "metadata": {},
   "source": [
    "We can look again at the land/ocean fluxes. We now exclude the prior uncertainty since it's so wide:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a8532c-6c9b-4b29-9d3f-eef3ecc57eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "land_ocean_flux_posterior <- x_to_land_ocean_flux(colMeans(x_samples), x_samples)\n",
    "\n",
    "options(repr.plot.width = 6, repr.plot.height = 4, repr.plot.res = 300)\n",
    "bind_rows(\n",
    "    land_ocean_flux_true %>%\n",
    "        mutate(source = 'Truth'),\n",
    "    land_ocean_flux_prior %>%\n",
    "        mutate(source = 'Prior', flux_q025 = NA, flux_q975 = NA),\n",
    "    land_ocean_flux_mode %>%\n",
    "        mutate(source = 'Posterior (mode)'),  \n",
    "    land_ocean_flux_posterior %>%\n",
    "        mutate(source = 'Posterior (full)')    \n",
    ") %>%\n",
    "    ggplot(aes(time, colour = source)) +\n",
    "        geom_line(mapping = aes(y = flux)) +\n",
    "        geom_line(mapping = aes(y = flux_q025), linetype = 'dashed', na.rm = TRUE) +\n",
    "        geom_line(mapping = aes(y = flux_q975), linetype = 'dashed', na.rm = TRUE) +\n",
    "        facet_wrap(~ region_type, ncol = 1, scales = 'free_y') +\n",
    "        labs(x = 'Time', y = 'Flux [PgC/year]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9200f2a6-1033-4d6c-8cd0-4e9a97bfb935",
   "metadata": {},
   "source": [
    "Here it seems there's not such a big difference between the posterior based on the posterior mode of ${\\boldsymbol \\theta}$ and the full posterior. We can instead look at regional fluxes to see if it makes more of a difference. Below we look at two ocean regions that are very poorly constrained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674571c1-6245-4e30-a75c-a1af0d2bccb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "regional_flux_true <- x_to_regional_flux(x_true)\n",
    "regional_flux_prior <- x_to_regional_flux(rep(0, ncol(H)))\n",
    "regional_flux_mode <- x_to_regional_flux(x_hat_mode, x_samples_mode)\n",
    "regional_flux_posterior <- x_to_regional_flux(colMeans(x_samples), x_samples)\n",
    "\n",
    "options(repr.plot.width = 6, repr.plot.height = 4, repr.plot.res = 300)\n",
    "bind_rows(\n",
    "    regional_flux_true %>%\n",
    "        mutate(source = 'Truth'),\n",
    "    regional_flux_prior %>%\n",
    "        mutate(source = 'Prior'),\n",
    "    regional_flux_mode %>%\n",
    "        mutate(source = 'Posterior (mode)'),  \n",
    "    regional_flux_posterior %>%\n",
    "        mutate(source = 'Posterior (full)')    \n",
    ") %>%\n",
    "    filter(\n",
    "        region_index %in% c(17, 20)\n",
    "    ) %>%\n",
    "    ggplot(aes(time, colour = source)) +\n",
    "        geom_line(mapping = aes(y = flux)) +\n",
    "        geom_line(mapping = aes(y = flux_q025), linetype = 'dashed', na.rm = TRUE) +\n",
    "        geom_line(mapping = aes(y = flux_q975), linetype = 'dashed', na.rm = TRUE) +\n",
    "        facet_wrap(~ region_name, ncol = 1, scales = 'free_y') +\n",
    "        labs(x = 'Time', y = 'Flux [PgC/year]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6571e8-6a5c-4e23-ae26-94a72dc56faf",
   "metadata": {},
   "source": [
    "In these regions, the full posterior uncertainty is somewhat wider than the uncertainty from the mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4462ef7-6db1-46e7-9fc3-39889330d6bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "R"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
